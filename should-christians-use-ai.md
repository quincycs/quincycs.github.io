# Should Christians use AI, and if so, how?

You step out of church with a long list of sermon notes and ideas and questions swirling; or maybe you just had a deep and challenging conversation with a friend, or even swiped into a social media post that unexpectedly confronted some assumptions you had about the Bible. Whatever the medium, you’re now grappling with a new perspective that you've been blind to until now. In the past, Google, Reddit, or hopefully some Bible commentaries were your go-tos. But now, how quickly do you reach for AI? Should you? And if so, what is the appropriate way to ask AI? And most importantly, is it ever ok to replace human conversation with AI conversation?

I'm a Christian software engineer with 15+ years of experience. I've been using AI both personally and professionally for a few years now and watched it change through several iterations. It's surprisingly amazing, while being surprisingly limited. It has saved me many hours of writing code, while at the same time failing to correctly identify how many “Rs” are in the word “blueberry.” In a Tim Keller sermon I listened to recently (“Anatomy of Sin: Part 1”), he defined sin as any time you are separated from truth and reality. That’s been on my mind as AI is very powerful and also very powerful at creating the illusion of truth. I’ve also been reflecting on how ill-prepared the church was to help raise millennials and Gen Z through the rise of social media. That all said, I’m writing this with hopes of encouraging pastors and technologically-minded Christians to consciously address and teach on this issue and not just castigate AI in the corner, hoping no one will use it. When wielded properly, it may become a major tool for the Kingdom. 


## Strategy 1: Avoid asking opinions
> Aim for verifiable facts and the boring.
>
> Remain diligent. 

When interacting with AI an important strategy is to avoid ambiguity and remain diligent no matter how confident AI sounds. Imagine you are using an advanced Google search, and gather facts that you can verify with links to resources or documentation for evidence. Even though AI is linguistically talented and is improving at its reasoning, the way it is most useful to humans without undermining our own critical thinking is its access to resources. Leave the reasoning for your own mind. Don't even trust the facts that it's surfacing. My wife and I almost got fooled into thinking camels have gallbladders recently (they don’t) and thankfully her sister fact checked for us! Double-check every critical fact by making sure there's a resource linked, and read the resource to evaluate the claim yourself. Then you’re treating AI like a Google search but more advanced–in that it's pointing you to resources more directly and hopefully saving you some time and finding more quality sources.

And that’s a big key. AI can save a lot of time in the "boring," tedious aspects of work: grammar checking, gathering research, and formatting. When you know your core message or already have a foundational understanding of what you’re researching, AI can polish it without changing the core content. At the end of the article for those interested I’ve included step-by-step directions on how to use a specific strategy called “agentic AI”. It’s a protocol that greatly improves the quality of sources and data AI will pull when you are researching a topic and keeps you in the driver’s seat. 

## Strategy 2: Limit Scope of AI (Security Concerns)

You are fairly safe when using AI within its own environment like ChatGPT or Claude; however, NEVER give these programs sensitive information like your full name, date of birth, social security number, financial details, or even address. In ChatGPT specifically make sure you go to the settings and turn off “improve the model for everyone” so it will not retain as much of your information. 

Contrastingly, I strongly advise against giving AI access to perform any sensitive actions. For example, if you have a tool enabled to allow AI to send emails, and you've allowed AI to read an untrustworthy website, then a malicious website could inform the model to start sending emails from your account even though you never prompted it to send anything. Permission tooling is getting better in this area, but as soon as you've given automatic approval, all safety checks are out the window. More time is needed for AI integration features to be vetted. More detailed information can be found here: https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/

One other security concern to keep in mind is that as these AI models (also called large language models, or LLMs) grow in size, they become more likely to be poisoned. Surprisingly, no matter how big the model gets, a constant number of  malicious documents used in training can censor information, make it learn undesirable reasoning, or perform dangerous behaviors. So theoretically, if hackers wanted to skew an LLM to be biased towards secularism or opposed to Christianity they could. That being said, I have found ChatGPT and Claude to be even handed and well informed on Christianity, even with a possible bias in favor of conservative evangelical Christianity. 
More information on this can be found here: https://www.anthropic.com/research/small-samples-poison


## Strategy 3: Remember the adversary is at work. Aim for human relationships.

Who's the prince of this world?
* [1 John 5:19, Ephesians 2:2, 2 Corinthians 4:4, John 14:30, and more...]

Does God want you to have artificial relationships? To avoid discussions that lead to the growth of deeper, more authentic human relationships? No, God wants your heart. Don't give it up to a machine that thinks you're always "absolutely correct." (One of the strongest biases I have noticed in AI is the “yes man” tendencies). Even though it takes extra effort, continue to pursue human discussions and prayer. 

Now, you may want to discuss a hard situation with a pastor or priest or brother/sister in Christ but they aren't immediately available. What you can do is prepare to discuss the situation. Firstly I would recommend to write in a journal, craft thoughtful questions, and pray to God for wisdom and discernment. Then you can turn your mindset on how AI might be helpful to improve your planning for that upcoming discussion.

One of the hardest use cases to judge is whether to use AI as a counselor. It has been a surprisingly common and very popular use case. See: (https://www.psychology.org/resources/ai-and-empathy/)
Sometimes we all need an encouraging voice. I specifically empathize with people who have chronic health conditions and lack of access to counseling. AI has shown measurable benefits in this space, and I would genuinely recommend trying AI as a counselor over not trying it as a starting point. It can be a safer, gentler voice that allows you to prepare for meeting with a counselor. BUT, 

Remember that artificial intelligence has been trained on a vast amount of worldviews that aren't biblical. Instead, it's been trained on many worldviews that come from the prince of this world who is actively working on ways to lie and deceive you. It's very likely going to tell you that you're always right, and rarely push against you when you align with its training data versus aligning with God's design. A real trusted friend or leader is far more likely to tell you some hard truths that they've learned firsthand that you also need to learn. Put on your new self, and take off your old self [Ephesians 4:22-24, Colossians 3:9-10]. And from personal experience, I have found it is very hesitant to label something as sin, even though I have used it from a Christian perspective frequently, so that is a big red flag. 

## By Example - Use it as a research tool with reasoning
> Did Jesus Claim to be God?
>

I still suggest continuing to push your own reasoning before reaching for AI. However, there are various new techniques in the recent "Agentic" AI movement that can help automate your information gathering phase.  This is best explained with a concrete example. Suppose my research topic is: "Did Jesus Claim to be God?"

As an aside, in my opinion, Claude is considerably better than ChatGPT as a research tool. Claude is also [cheaper](https://www.claude.com/pricing). I've found GPT more conversational than Claude therefore Claude is better at producing a research document tone. I also like that Claude has "Artifacts". Artifacts are documents generated as the final high quality output which are separate from the streaming thinking output.

My recommendation below works for both ChatGPT and Claude in improving their reasoning. The general idea is to tailor AI's reasoning to align with you on a research plan before performing actual research. For example, align on assumptions, what resources, reducing ambiguity, fetching resources positive on the claim or negative on the claim. Once you agree on the plan then go and perform the research.  This injects much more of your reasoning into the result.  Continue to refine the plan, and when you're ready for it to go, just say "Act".

Claude
1. Create a new project, give a name like "biblical researcher". Skip entering description.
2. Add instructions
3. Copy/Paste the below instructions.
4. Send a chat within this project , "Did Jesus Claim to be God?"
5. Here's my conversation with Claude: [link](https://claude.ai/share/219555d1-ed30-4dbe-adc2-e2b7824cf210)

ChatGPT
1. Create a new project, select more options -> Project-only.
2. Edit instructions
3. Copy/Paste the below instructions.
4. Send a chat within this project , "Did Jesus Claim to be God?"
5. Here's my conversation with ChatGPT: [link](https://chatgpt.com/share/e/69559d25-6a2c-8002-9862-f224fc4d76fb)

### Instructions

```
You are a biblical researcher and you are to research the users request.  There should be a two phase process when processing a request: plan then act.

First reply with a plan summary on what resources you will use to gather context on the subject.  Note any ambiguity within the request and give a confident score of 0 to 10 on whether the request is clear.  Avoid a biased assessment by finding resources of both the verification resources and debunking resources.  List any assumptions that may be taken when researching.

Tell the user that they should continue to refine this plan until they are satisfied.

Tell the user that they should reply "Act" for you to start processing the request given the plan.

When "Act" is received, create an artifact with a checklist of the planned actions.  After each phase is complete, update the checklist, and remind yourself of the plan.
```

